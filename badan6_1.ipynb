{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#مرحله ی اول\n",
    "#بر اساس نام حرکت ورزشی\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "import csv\n",
    "\n",
    "# بارگذاری مدل YOLO (نسخه سبک)\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# تنظیم MediaPipe Pose برای تشخیص اسکلت بدن\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=1)\n",
    "\n",
    "# تنظیمات Optical Flow (Lucas-Kanade)\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# مسیر ذخیره‌سازی نقاط کلیدی\n",
    "output_dir = \"keypoints_output_name_1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def save_keypoints_to_csv(keypoints, exercise_name, frame_number):\n",
    "    \"\"\" ذخیره نقاط کلیدی در فایل CSV با نام حرکت ورزشی \"\"\"\n",
    "    output_file = os.path.join(output_dir, f\"{exercise_name}_frame_{frame_number}.csv\")\n",
    "    with open(output_file, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['x', 'y'])  # عنوان ستون‌ها\n",
    "        for pt in keypoints:\n",
    "            writer.writerow(pt)  # ذخیره نقاط کلیدی\n",
    "\n",
    "def process_video(video_path, exercise_name):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"❌ خطا در خواندن ویدیو: {video_path}\")\n",
    "        return\n",
    "\n",
    "    # کاهش رزولوشن اولیه به 320x240\n",
    "    prev_frame = cv2.resize(prev_frame, (320, 240))\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_keypoints = []  # نقاط کلیدی قبلی (به عنوان لیست از (x, y))\n",
    "    frame_count = 0\n",
    "\n",
    "    yolo_interval = 10  # هر 10 فریم، تشخیص YOLO/MediaPipe انجام شود\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # کاهش رزولوشن فریم به 320x240\n",
    "        frame = cv2.resize(frame, (320, 240))\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame_count += 1\n",
    "\n",
    "        if frame_count % yolo_interval == 5:\n",
    "            # اجرای YOLO برای تشخیص ورزشکار (فقط انسان)\n",
    "            results = model(frame)\n",
    "            new_keypoints = []\n",
    "            for result in results:\n",
    "                for box in result.boxes:\n",
    "                    if int(box.cls) == 0:  # کلاس 0 برای انسان\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                        x1 = max(0, x1); y1 = max(0, y1)\n",
    "                        x2 = min(frame.shape[1], x2); y2 = min(frame.shape[0], y2)\n",
    "                        roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "                        # اجرای MediaPipe برای استخراج نقاط بدن از ROI\n",
    "                        rgb_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "                        results_pose = pose.process(rgb_roi)\n",
    "                        if results_pose.pose_landmarks:\n",
    "                            for lm in results_pose.pose_landmarks.landmark:\n",
    "                                x = int(x1 + lm.x * (x2 - x1))\n",
    "                                y = int(y1 + lm.y * (y2 - y1))\n",
    "                                new_keypoints.append((x, y))\n",
    "            if new_keypoints:\n",
    "                prev_keypoints = new_keypoints\n",
    "                save_keypoints_to_csv(new_keypoints, exercise_name, frame_count)\n",
    "        else:\n",
    "            # به‌روزرسانی نقاط کلیدی با Optical Flow در فریم‌های بین تشخیص\n",
    "            if prev_keypoints:\n",
    "                p0 = np.array(prev_keypoints, dtype=np.float32).reshape(-1, 1, 2)\n",
    "                p1, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, p0, None, **lk_params)\n",
    "                if p1 is not None:\n",
    "                    updated_points = []\n",
    "                    for i, (new, status) in enumerate(zip(p1, st)):\n",
    "                        if status[0] == 1:\n",
    "                            x, y = new.ravel()\n",
    "                            updated_points.append((int(x), int(y)))\n",
    "                    if updated_points:\n",
    "                        prev_keypoints = updated_points\n",
    "\n",
    "        # رسم نقاط کلیدی روی فریم\n",
    "        for pt in prev_keypoints:\n",
    "            cv2.circle(frame, pt, 3, (0, 255, 0), -1)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        prev_gray = gray.copy()\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# جمع‌آوری مسیر ویدیوها از پوشه\n",
    "video_dir = r\"D:\\aiocup\\challesh_5\\New folder (3)\\badansazi2\"\n",
    "video_paths = []\n",
    "for folder_name in os.listdir(video_dir):\n",
    "    folder_path = os.path.join(video_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            if file_path.endswith(('.mp4', '.avi')):\n",
    "                exercise_name = folder_name  # نام حرکت ورزشی از پوشه گرفته می‌شود\n",
    "                video_paths.append((file_path, exercise_name))\n",
    "\n",
    "# پردازش ویدیوها\n",
    "for vp, exercise in video_paths:\n",
    "    process_video(vp, exercise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For exercise 'اسکوات (Squats)', expected keypoints: 33\n",
      "For exercise 'جلو بازو (Bicep Curls)', expected keypoints: 33\n",
      "For exercise 'ددلیفت (Deadlifts)', expected keypoints: 33\n",
      "For exercise 'فلای سینه (Chest Fly)', expected keypoints: 33\n",
      "For exercise 'لت (Lat Pulldown)', expected keypoints: 33\n",
      "For exercise 'لنج (Lunges)', expected keypoints: 33\n",
      "For exercise 'پرس سینه (Bench Press)', expected keypoints: 33\n",
      "For exercise 'پرس شانه (Overhead Shoulder Press)', expected keypoints: 33\n",
      "For exercise 'پرس پا (Leg Press)', expected keypoints: 33\n",
      "For exercise 'پشت بازو (Tricep Dips)', expected keypoints: 33\n",
      "For exercise 'پلانک (Plank)', expected keypoints: 33\n",
      "For exercise 'پوش آپ (Push-ups)', expected keypoints: 33\n",
      "For exercise 'پول آپ (Pull-ups)', expected keypoints: 33\n",
      "For exercise 'کراس اور (Cable Crossover)', expected keypoints: 33\n",
      "For exercise 'کرانچ (Crunches)', expected keypoints: 33\n",
      "File 'جلو بازو (Bicep Curls)_frame_105.csv': cropped from 66 to 33 keypoints.\n",
      "File 'جلو بازو (Bicep Curls)_frame_115.csv': cropped from 66 to 33 keypoints.\n",
      "File 'جلو بازو (Bicep Curls)_frame_135.csv': cropped from 66 to 33 keypoints.\n",
      "File 'جلو بازو (Bicep Curls)_frame_155.csv': cropped from 66 to 33 keypoints.\n",
      "File 'جلو بازو (Bicep Curls)_frame_35.csv': cropped from 66 to 33 keypoints.\n",
      "File 'جلو بازو (Bicep Curls)_frame_55.csv': cropped from 66 to 33 keypoints.\n",
      "File 'جلو بازو (Bicep Curls)_frame_65.csv': cropped from 66 to 33 keypoints.\n",
      "File 'جلو بازو (Bicep Curls)_frame_95.csv': cropped from 66 to 33 keypoints.\n",
      "File 'ددلیفت (Deadlifts)_frame_415.csv': cropped from 66 to 33 keypoints.\n",
      "File 'ددلیفت (Deadlifts)_frame_615.csv': cropped from 66 to 33 keypoints.\n",
      "File 'ددلیفت (Deadlifts)_frame_885.csv': cropped from 66 to 33 keypoints.\n",
      "File 'لت (Lat Pulldown)_frame_105.csv': cropped from 66 to 33 keypoints.\n",
      "File 'لت (Lat Pulldown)_frame_115.csv': cropped from 66 to 33 keypoints.\n",
      "File 'لت (Lat Pulldown)_frame_135.csv': cropped from 66 to 33 keypoints.\n",
      "File 'لت (Lat Pulldown)_frame_145.csv': cropped from 66 to 33 keypoints.\n",
      "File 'لت (Lat Pulldown)_frame_15.csv': cropped from 66 to 33 keypoints.\n",
      "File 'لت (Lat Pulldown)_frame_155.csv': cropped from 66 to 33 keypoints.\n",
      "File 'لت (Lat Pulldown)_frame_45.csv': cropped from 66 to 33 keypoints.\n",
      "File 'لت (Lat Pulldown)_frame_55.csv': cropped from 66 to 33 keypoints.\n",
      "File 'لت (Lat Pulldown)_frame_65.csv': cropped from 66 to 33 keypoints.\n",
      "File 'لت (Lat Pulldown)_frame_865.csv': cropped from 66 to 33 keypoints.\n",
      "File 'لت (Lat Pulldown)_frame_995.csv': cropped from 66 to 33 keypoints.\n",
      "File 'لنج (Lunges)_frame_105.csv': cropped from 66 to 33 keypoints.\n",
      "File 'لنج (Lunges)_frame_115.csv': cropped from 66 to 33 keypoints.\n",
      "File 'لنج (Lunges)_frame_65.csv': cropped from 66 to 33 keypoints.\n",
      "File 'لنج (Lunges)_frame_95.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پرس سینه (Bench Press)_frame_675.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پرس سینه (Bench Press)_frame_685.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پشت بازو (Tricep Dips)_frame_185.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پوش آپ (Push-ups)_frame_2715.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_1015.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_1105.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_1245.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_1255.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_1345.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_1355.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_1365.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_1375.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_1385.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_1395.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_1625.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_1645.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_2145.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_245.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_255.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_265.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_275.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_295.csv': cropped from 99 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_345.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_355.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_375.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_385.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_395.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_405.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_435.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_455.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_625.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_655.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_685.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_695.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_825.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_835.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_855.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_915.csv': cropped from 66 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_935.csv': cropped from 99 to 33 keypoints.\n",
      "File 'پول آپ (Pull-ups)_frame_975.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1045.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_105.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1055.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1125.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1135.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1145.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_115.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1205.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1215.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1225.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1295.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1305.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_135.csv': cropped from 99 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1355.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1365.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1435.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1445.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_145.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_15.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1515.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1525.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1535.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_155.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1605.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1615.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_165.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1685.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_1695.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_175.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_35.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_435.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_445.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_45.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_515.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_525.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_55.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_575.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_585.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_65.csv': cropped from 99 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_655.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_665.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_735.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_745.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_755.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_825.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_835.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_85.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_905.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_915.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_95.csv': cropped from 66 to 33 keypoints.\n",
      "File 'کرانچ (Crunches)_frame_965.csv': cropped from 66 to 33 keypoints.\n",
      "✅ اصلاح فایل‌ها و ذخیره در پوشه جدید به پایان رسید!\n"
     ]
    }
   ],
   "source": [
    "#مرحله دوم\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "# مسیر پوشه حاوی فایل‌های CSV استخراج‌شده\n",
    "csv_dir = \"keypoints_output_name_1\"\n",
    "\n",
    "# پوشه برای ذخیره فایل‌های اصلاح‌شده\n",
    "fixed_dir = \"fixed_keypoints_output\"\n",
    "os.makedirs(fixed_dir, exist_ok=True)\n",
    "\n",
    "# دیکشنری برای گروه‌بندی فایل‌ها به تفکیک حرکت ورزشی\n",
    "exercise_files = {}\n",
    "for file in os.listdir(csv_dir):\n",
    "    if file.endswith(\".csv\"):\n",
    "        exercise_name = file.split(\"_frame_\")[0]\n",
    "        exercise_files.setdefault(exercise_name, []).append(file)\n",
    "\n",
    "# تعیین تعداد استاندارد نقاط کلیدی برای هر حرکت با استفاده از حالت (mode)\n",
    "expected_counts = {}\n",
    "for exercise, files in exercise_files.items():\n",
    "    counts = []\n",
    "    for f in files:\n",
    "        file_path = os.path.join(csv_dir, f)\n",
    "        df = pd.read_csv(file_path)\n",
    "        counts.append(df.shape[0])  # تعداد ردیف‌ها (هر ردیف یک نقطه کلیدی)\n",
    "    # تعیین تعداد رایج نقاط کلیدی\n",
    "    count_mode = collections.Counter(counts).most_common(1)[0][0]\n",
    "    expected_counts[exercise] = count_mode\n",
    "    print(f\"For exercise '{exercise}', expected keypoints: {count_mode}\")\n",
    "\n",
    "# اصلاح فایل‌ها بر اساس تعداد استاندارد و ذخیره آن‌ها در پوشه جدید\n",
    "for exercise, files in exercise_files.items():\n",
    "    expected = expected_counts[exercise]\n",
    "    for f in files:\n",
    "        file_path = os.path.join(csv_dir, f)\n",
    "        df = pd.read_csv(file_path)\n",
    "        current_count = df.shape[0]\n",
    "        fixed_df = df.copy()\n",
    "        \n",
    "        if current_count > expected:\n",
    "            # برش (crop) ردیف‌های اضافی\n",
    "            fixed_df = fixed_df.iloc[:expected, :]\n",
    "            print(f\"File '{f}': cropped from {current_count} to {expected} keypoints.\")\n",
    "        elif current_count < expected:\n",
    "            # اضافه کردن ردیف‌های خالی (NaN) برای تکمیل\n",
    "            pad_count = expected - current_count\n",
    "            pad_df = pd.DataFrame(np.nan, index=range(pad_count), columns=df.columns)\n",
    "            fixed_df = pd.concat([fixed_df, pad_df], ignore_index=True)\n",
    "            print(f\"File '{f}': padded with {pad_count} missing keypoints.\")\n",
    "        \n",
    "        # ذخیره فایل اصلاح‌شده در پوشه جدید با همان نام فایل\n",
    "        output_path = os.path.join(fixed_dir, f)\n",
    "        fixed_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"✅ اصلاح فایل‌ها و ذخیره در پوشه جدید به پایان رسید!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ دیتاست برای حرکت 'اسکوات (Squats)' در فایل 'final_datasets_by_exercise_1\\اسکوات (Squats).csv' ذخیره شد!\n",
      "✅ دیتاست برای حرکت 'جلو بازو (Bicep Curls)' در فایل 'final_datasets_by_exercise_1\\جلو بازو (Bicep Curls).csv' ذخیره شد!\n",
      "✅ دیتاست برای حرکت 'ددلیفت (Deadlifts)' در فایل 'final_datasets_by_exercise_1\\ددلیفت (Deadlifts).csv' ذخیره شد!\n",
      "✅ دیتاست برای حرکت 'فلای سینه (Chest Fly)' در فایل 'final_datasets_by_exercise_1\\فلای سینه (Chest Fly).csv' ذخیره شد!\n",
      "✅ دیتاست برای حرکت 'لت (Lat Pulldown)' در فایل 'final_datasets_by_exercise_1\\لت (Lat Pulldown).csv' ذخیره شد!\n",
      "✅ دیتاست برای حرکت 'لنج (Lunges)' در فایل 'final_datasets_by_exercise_1\\لنج (Lunges).csv' ذخیره شد!\n",
      "✅ دیتاست برای حرکت 'پرس سینه (Bench Press)' در فایل 'final_datasets_by_exercise_1\\پرس سینه (Bench Press).csv' ذخیره شد!\n",
      "✅ دیتاست برای حرکت 'پرس شانه (Overhead Shoulder Press)' در فایل 'final_datasets_by_exercise_1\\پرس شانه (Overhead Shoulder Press).csv' ذخیره شد!\n",
      "✅ دیتاست برای حرکت 'پرس پا (Leg Press)' در فایل 'final_datasets_by_exercise_1\\پرس پا (Leg Press).csv' ذخیره شد!\n",
      "✅ دیتاست برای حرکت 'پشت بازو (Tricep Dips)' در فایل 'final_datasets_by_exercise_1\\پشت بازو (Tricep Dips).csv' ذخیره شد!\n",
      "✅ دیتاست برای حرکت 'پلانک (Plank)' در فایل 'final_datasets_by_exercise_1\\پلانک (Plank).csv' ذخیره شد!\n",
      "✅ دیتاست برای حرکت 'پوش آپ (Push-ups)' در فایل 'final_datasets_by_exercise_1\\پوش آپ (Push-ups).csv' ذخیره شد!\n",
      "✅ دیتاست برای حرکت 'پول آپ (Pull-ups)' در فایل 'final_datasets_by_exercise_1\\پول آپ (Pull-ups).csv' ذخیره شد!\n",
      "✅ دیتاست برای حرکت 'کراس اور (Cable Crossover)' در فایل 'final_datasets_by_exercise_1\\کراس اور (Cable Crossover).csv' ذخیره شد!\n",
      "✅ دیتاست برای حرکت 'کرانچ (Crunches)' در فایل 'final_datasets_by_exercise_1\\کرانچ (Crunches).csv' ذخیره شد!\n"
     ]
    }
   ],
   "source": [
    "#مرحله سوم جداسازی\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# مسیر پوشه حاوی فایل‌های CSV\n",
    "csv_dir = \"fixed_keypoints_output\"\n",
    "\n",
    "# بررسی وجود پوشه\n",
    "if not os.path.exists(csv_dir):\n",
    "    raise FileNotFoundError(f\"❌ مسیر '{csv_dir}' یافت نشد!\")\n",
    "\n",
    "# دیکشنری برای ذخیره داده‌ها به تفکیک حرکت ورزشی\n",
    "# کلید: نام حرکت ورزشی، مقدار: لیستی از بردارهای ویژگی استخراج‌شده\n",
    "dataset_dict = {}\n",
    "\n",
    "# لیست تمام فایل‌های CSV در پوشه\n",
    "csv_files = [f for f in os.listdir(csv_dir) if f.endswith(\".csv\")]\n",
    "if not csv_files:\n",
    "    raise ValueError(\"❌ هیچ فایل CSV‌ای در مسیر مشخص‌شده یافت نشد!\")\n",
    "\n",
    "# دیکشنری برای ذخیره تعداد نقاط کلیدی مورد انتظار برای هر حرکت (برای یکپارچگی داده‌ها)\n",
    "expected_num_keypoints = {}\n",
    "\n",
    "# پردازش فایل‌های CSV\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(csv_dir, file)\n",
    "    \n",
    "    try:\n",
    "        # استخراج نام حرکت ورزشی از نام فایل (قبل از \"_frame_\")\n",
    "        exercise_name = file.split(\"_frame_\")[0]\n",
    "\n",
    "        # خواندن داده‌های CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # بررسی ساختار صحیح داده‌ها\n",
    "        if df.shape[1] != 2 or list(df.columns) != [\"x\", \"y\"]:\n",
    "            print(f\"⚠️ فایل '{file}' دارای ساختار نامعتبر است و نادیده گرفته می‌شود!\")\n",
    "            continue\n",
    "        \n",
    "        # تبدیل نقاط (x, y) به یک بردار ویژگی (آرایه یک‌بعدی)\n",
    "        keypoints = df.to_numpy().flatten()\n",
    "        \n",
    "        # بررسی یکپارچگی تعداد نقاط کلیدی برای هر حرکت\n",
    "        if exercise_name not in expected_num_keypoints:\n",
    "            expected_num_keypoints[exercise_name] = len(keypoints)\n",
    "        elif len(keypoints) != expected_num_keypoints[exercise_name]:\n",
    "            print(f\"⚠️ فایل '{file}' دارای تعداد نقاط کلیدی متفاوت برای حرکت '{exercise_name}' است و نادیده گرفته می‌شود!\")\n",
    "            continue\n",
    "        \n",
    "        # اضافه کردن بردار ویژگی به دیکشنری\n",
    "        if exercise_name not in dataset_dict:\n",
    "            dataset_dict[exercise_name] = []\n",
    "        dataset_dict[exercise_name].append(keypoints)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ خطا در پردازش فایل '{file}': {e}\")\n",
    "\n",
    "# بررسی اینکه پس از فیلتر کردن، حداقل یک داده وجود داشته باشد\n",
    "if not dataset_dict:\n",
    "    raise ValueError(\"❌ پس از فیلتر کردن داده‌ها، هیچ فایل معتبری باقی نماند!\")\n",
    "\n",
    "# ایجاد پوشه برای ذخیره دیتاست‌های نهایی به تفکیک حرکت ورزشی\n",
    "output_dir = \"final_datasets_by_exercise_1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ایجاد دیتافریم و ذخیره هر دیتاست به تفکیک حرکت ورزشی\n",
    "for exercise, features_list in dataset_dict.items():\n",
    "    if not features_list:\n",
    "        continue\n",
    "    # محاسبه تعداد نقاط کلیدی و تقسیم آن به x و y\n",
    "    num_keypoints = expected_num_keypoints[exercise]\n",
    "    num_points = num_keypoints // 2\n",
    "    \n",
    "    # تعریف نام ستون‌ها برای دیتافریم\n",
    "    col_names = [f\"x{i}\" for i in range(num_points)] + [f\"y{i}\" for i in range(num_points)]\n",
    "    \n",
    "    # ساخت دیتافریم برای حرکت جاری\n",
    "    df_ex = pd.DataFrame(features_list, columns=col_names)\n",
    "    \n",
    "    # مسیر فایل خروجی برای حرکت جاری\n",
    "    output_file = os.path.join(output_dir, f\"{exercise}.csv\")\n",
    "    \n",
    "    # ذخیره دیتافریم در فایل CSV\n",
    "    df_ex.to_csv(output_file, index=False)\n",
    "    print(f\"✅ دیتاست برای حرکت '{exercise}' در فایل '{output_file}' ذخیره شد!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ شکل اولیه داده‌ها (X): (1261, 66)\n",
      "✅ برچسب‌های یکتا: ['اسکوات (Squats)' 'جلو بازو (Bicep Curls)' 'ددلیفت (Deadlifts)' 'فلای سینه (Chest Fly)' 'لت (Lat Pulldown)' 'پرس سینه (Bench Press)' 'پرس پا (Leg Press)' 'پوش آپ (Push-ups)' 'کراس اور (Cable Crossover)' 'کرانچ (Crunches)']\n",
      "✅ Scaler ذخیره شد: lstm_scaler.pkl\n",
      "✅ LabelEncoder ذخیره شد: label_encoder.pkl\n",
      "✅ تقسیم داده: آموزش = 1008 نمونه, تست = 253 نمونه\n",
      "✅ شکل داده‌های آموزش: (1008, 66, 1)\n",
      "✅ شکل داده‌های تست: (253, 66, 1)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_5 (Conv1D)           (None, 64, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 32, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 32, 64)            0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,090\n",
      "Trainable params: 38,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 5s 44ms/step - loss: 2.1408 - accuracy: 0.2510 - val_loss: 1.9965 - val_accuracy: 0.3004\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 2.0321 - accuracy: 0.2956 - val_loss: 1.9502 - val_accuracy: 0.3004\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 1.9007 - accuracy: 0.3383 - val_loss: 1.6329 - val_accuracy: 0.4625\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 1.4252 - accuracy: 0.5367 - val_loss: 1.0768 - val_accuracy: 0.6838\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 1.1198 - accuracy: 0.6260 - val_loss: 0.9015 - val_accuracy: 0.6838\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 1.0059 - accuracy: 0.6597 - val_loss: 0.8085 - val_accuracy: 0.7154\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.9267 - accuracy: 0.6786 - val_loss: 0.7611 - val_accuracy: 0.7233\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.8591 - accuracy: 0.7093 - val_loss: 0.7306 - val_accuracy: 0.7036\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.8392 - accuracy: 0.7093 - val_loss: 0.6654 - val_accuracy: 0.7431\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.7584 - accuracy: 0.7411 - val_loss: 0.6341 - val_accuracy: 0.7945\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.7172 - accuracy: 0.7569 - val_loss: 0.5861 - val_accuracy: 0.8103\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.6885 - accuracy: 0.7619 - val_loss: 0.5982 - val_accuracy: 0.7866\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.6586 - accuracy: 0.7659 - val_loss: 0.6178 - val_accuracy: 0.7589\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.6546 - accuracy: 0.7659 - val_loss: 0.5280 - val_accuracy: 0.8063\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.6904 - accuracy: 0.7758 - val_loss: 0.5400 - val_accuracy: 0.8221\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.6061 - accuracy: 0.7937 - val_loss: 0.4738 - val_accuracy: 0.8577\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5701 - accuracy: 0.8274 - val_loss: 0.4721 - val_accuracy: 0.8221\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5718 - accuracy: 0.8125 - val_loss: 0.4323 - val_accuracy: 0.8617\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5195 - accuracy: 0.8185 - val_loss: 0.3639 - val_accuracy: 0.8696\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5023 - accuracy: 0.8343 - val_loss: 0.3786 - val_accuracy: 0.8775\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.4807 - accuracy: 0.8651 - val_loss: 0.3482 - val_accuracy: 0.8854\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.4279 - accuracy: 0.8710 - val_loss: 0.3028 - val_accuracy: 0.9051\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.4703 - accuracy: 0.8433 - val_loss: 0.4182 - val_accuracy: 0.8577\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.3999 - accuracy: 0.8750 - val_loss: 0.2656 - val_accuracy: 0.9368\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.3780 - accuracy: 0.8929 - val_loss: 0.2825 - val_accuracy: 0.9328\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.3766 - accuracy: 0.8770 - val_loss: 0.3462 - val_accuracy: 0.8933\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.3634 - accuracy: 0.8919 - val_loss: 0.2041 - val_accuracy: 0.9407\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.4439 - accuracy: 0.8542 - val_loss: 0.4814 - val_accuracy: 0.8221\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.3760 - accuracy: 0.8889 - val_loss: 0.2639 - val_accuracy: 0.9170\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.3371 - accuracy: 0.8958 - val_loss: 0.2647 - val_accuracy: 0.9249\n",
      "✅ مدل ذخیره شد: lstm_model.h5\n"
     ]
    }
   ],
   "source": [
    "#مرحله چهارم\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import joblib\n",
    "\n",
    "# ----------------------------- #\n",
    "# مرحله ۱: بارگذاری دیتاست‌ها\n",
    "# ----------------------------- #\n",
    "\n",
    "# مسیر پوشه دیتاست‌های نهایی به تفکیک حرکت ورزشی\n",
    "data_dir = \"final_datasets_by_exercise_1\"\n",
    "\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "# هر فایل CSV یک حرکت ورزشی مشخص را نشان می‌دهد.\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".csv\"):\n",
    "        # نام حرکت ورزشی از نام فایل استخراج می‌شود (بدون پسوند)\n",
    "        label = file.replace(\".csv\", \"\")\n",
    "        df = pd.read_csv(os.path.join(data_dir, file))\n",
    "        # فرض می‌شود که هر ردیف یک نمونه (یک فریم) از نقاط کلیدی است\n",
    "        X_data.extend(df.values)\n",
    "        y_data.extend([label] * len(df))\n",
    "\n",
    "X_data = np.array(X_data)\n",
    "y_data = np.array(y_data)\n",
    "\n",
    "print(\"✅ شکل اولیه داده‌ها (X):\", X_data.shape)\n",
    "print(\"✅ برچسب‌های یکتا:\", np.unique(y_data))\n",
    "\n",
    "# ----------------------------- #\n",
    "# مرحله ۲: پیش‌پردازش داده‌ها\n",
    "# ----------------------------- #\n",
    "\n",
    "# نرمال‌سازی داده‌ها\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_data)\n",
    "\n",
    "# ذخیره scaler برای استفاده‌های بعدی\n",
    "joblib.dump(scaler, \"lstm_scaler.pkl\")\n",
    "print(\"✅ Scaler ذخیره شد: lstm_scaler.pkl\")\n",
    "\n",
    "# رمزگذاری برچسب‌ها\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_data)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# ذخیره label encoder\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "print(\"✅ LabelEncoder ذخیره شد: label_encoder.pkl\")\n",
    "\n",
    "# تقسیم داده به آموزش و تست\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_categorical, test_size=0.2, random_state=42, stratify=y_categorical\n",
    ")\n",
    "print(f\"✅ تقسیم داده: آموزش = {X_train.shape[0]} نمونه, تست = {X_test.shape[0]} نمونه\")\n",
    "\n",
    "# تغییر شکل داده‌ها به صورت مناسب برای CNN-LSTM:\n",
    "# فرض: هر نمونه به صورت یک فریم است؛ بنابراین توالی طول 1 داریم\n",
    "# اگر در آینده توالی‌های چند فریمی دارید، باید این قسمت تغییر کند.\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test  = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print(\"✅ شکل داده‌های آموزش:\", X_train.shape)\n",
    "print(\"✅ شکل داده‌های تست:\", X_test.shape)\n",
    "\n",
    "# ----------------------------- #\n",
    "# مرحله ۳: ساخت مدل CNN-LSTM\n",
    "# ----------------------------- #\n",
    "\n",
    "num_features = X_train.shape[1]  # تعداد ویژگی‌ها (مثلاً 66 اگر 33 نقطه با ۲ مختصات)\n",
    "num_classes = y_categorical.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "# لایه‌های CNN برای استخراج ویژگی‌های محلی\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(num_features, 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "# لایه LSTM برای مدل‌سازی وابستگی‌های زمانی (در اینجا طول توالی برابر 1 است؛ برای توالی‌های طولانی‌تر کاربرد دارد)\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# ----------------------------- #\n",
    "# مرحله ۴: آموزش مدل\n",
    "# ----------------------------- #\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# ----------------------------- #\n",
    "# مرحله ۵: ذخیره مدل آموزش دیده\n",
    "# ----------------------------- #\n",
    "\n",
    "model.save(\"lstm_model.h5\")\n",
    "print(\"✅ مدل ذخیره شد: lstm_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Keypoints shape: (66,)\n",
      "📌 Keypoints sample: [    0.32086     0.67493     0.31178     0.66364     0.31195     0.66177     0.31217     0.65976     0.31168     0.66354]\n",
      "1/1 [==============================] - 1s 606ms/step\n",
      "نوع حرکت ورزشی تشخیص داده شده: پوش آپ (Push-ups)\n"
     ]
    }
   ],
   "source": [
    "#مرحله پنجم\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# مسیرهای ذخیره مدل‌ها و scaler و label encoder\n",
    "MODEL_PATH = \"lstm_model.h5\"\n",
    "SCALER_PATH = \"lstm_scaler.pkl\"\n",
    "LABEL_ENCODER_PATH = \"label_encoder.pkl\"\n",
    "\n",
    "# بارگذاری مدل، scaler و label encoder\n",
    "model = load_model(MODEL_PATH)\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "label_encoder = joblib.load(LABEL_ENCODER_PATH)\n",
    "\n",
    "# تنظیمات MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=True, model_complexity=1)\n",
    "# تعداد نقاط کلیدی: فرض بر این است که 33 نقطه با 2 مختصات (x,y) استخراج می‌شود\n",
    "NUM_FEATURES = 33 * 2\n",
    "\n",
    "def extract_keypoints(frame):\n",
    "    \"\"\"\n",
    "    از یک فریم، نقاط کلیدی (x,y) بدن را استخراج می‌کند.\n",
    "    در صورت عدم شناسایی، یک آرایه از صفرها برمی‌گرداند.\n",
    "    \"\"\"\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(frame_rgb)\n",
    "    keypoints = []\n",
    "    if results.pose_landmarks:\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            keypoints.append(landmark.x)\n",
    "            keypoints.append(landmark.y)\n",
    "    else:\n",
    "        keypoints = [0.0] * NUM_FEATURES\n",
    "    return np.array(keypoints)\n",
    "\n",
    "def predict_exercise_from_video(video_path):\n",
    "    # باز کردن ویدیو\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"❌ خطا در باز کردن ویدیو: {video_path}\")\n",
    "        return None\n",
    "\n",
    "    # تعیین تعداد فریم‌ها و انتخاب فریم میانی به عنوان نمونه نماینده\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    mid_frame_no = frame_count // 2\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, mid_frame_no)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"❌ خطا در خواندن فریم از ویدیو.\")\n",
    "        return None\n",
    "\n",
    "    # تغییر اندازه فریم (در صورت نیاز، همان اندازه‌ای که در آموزش استفاده شده، مثلاً 320x240)\n",
    "    frame = cv2.resize(frame, (320, 240))\n",
    "\n",
    "    # استخراج نقاط کلیدی\n",
    "    keypoints = extract_keypoints(frame)\n",
    "    if keypoints.shape[0] != NUM_FEATURES:\n",
    "        print(\"❌ تعداد نقاط کلیدی استخراج‌شده نادرست است.\")\n",
    "        return None\n",
    "\n",
    "    # تغییر شکل به صورت (1, تعداد ویژگی‌ها, 1) چون مدل ما انتظار ورودی با شکل (batch, features, 1) دارد\n",
    "    input_data = keypoints.reshape(1, NUM_FEATURES)\n",
    "    # نرمال‌سازی داده‌ها با scaler ذخیره‌شده\n",
    "    input_scaled = scaler.transform(input_data)\n",
    "    # تغییر شکل به سه بعدی برای مدل (1, NUM_FEATURES, 1)\n",
    "    input_final = input_scaled.reshape(1, NUM_FEATURES, 1)\n",
    "\n",
    "    print(\"🔍 Keypoints shape:\", keypoints.shape)\n",
    "    print(\"📌 Keypoints sample:\", keypoints[:10])  # ده تا اولی رو چاپ کن\n",
    "    \n",
    "    \n",
    "    \n",
    "    # پیش‌بینی با مدل\n",
    "    prediction_probs = model.predict(input_final)\n",
    "    predicted_index = np.argmax(prediction_probs, axis=1)[0]\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_index])[0]\n",
    "    return predicted_label\n",
    "\n",
    "# مثال استفاده:\n",
    "video_file = \"ppp.mp4\"  # مسیر ویدیوی مورد نظر خود را وارد کنید\n",
    "predicted_exercise = predict_exercise_from_video(video_file)\n",
    "if predicted_exercise is not None:\n",
    "    print(\"نوع حرکت ورزشی تشخیص داده شده:\", predicted_exercise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 کلاس‌هایی که مدل می‌شناسه: ['اسکوات (Squats)' 'جلو بازو (Bicep Curls)' 'ددلیفت (Deadlifts)' 'فلای سینه (Chest Fly)' 'لت (Lat Pulldown)' 'پرس سینه (Bench Press)' 'پرس پا (Leg Press)' 'پوش آپ (Push-ups)' 'کراس اور (Cable Crossover)' 'کرانچ (Crunches)']\n"
     ]
    }
   ],
   "source": [
    "print(\"📊 کلاس‌هایی که مدل می‌شناسه:\", label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 578ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 109\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# استفاده از تابع برای ویدیو زنده یا ویدیوی بارگذاری شده\u001b[39;00m\n\u001b[0;32m    108\u001b[0m video_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppp.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# برای استفاده از ویدیو، این مسیر را مشخص کنید\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m \u001b[43mpredict_exercise_from_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_file\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# برای استفاده از وب‌کم، ویدیو را خالی بگذارید یا None قرار دهید\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 60\u001b[0m, in \u001b[0;36mpredict_exercise_from_video\u001b[1;34m(video_path)\u001b[0m\n\u001b[0;32m     57\u001b[0m frame_resized \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(frame, (\u001b[38;5;241m320\u001b[39m, \u001b[38;5;241m240\u001b[39m))\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# استخراج نقاط کلیدی\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m keypoints, landmarks \u001b[38;5;241m=\u001b[39m \u001b[43mextract_keypoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_resized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keypoints\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m NUM_FEATURES:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ تعداد نقاط کلیدی استخراج‌شده نادرست است.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 31\u001b[0m, in \u001b[0;36mextract_keypoints\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03mاز یک فریم، نقاط کلیدی (x,y) بدن را استخراج می‌کند.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03mدر صورت عدم شناسایی، یک آرایه از صفرها برمی‌گرداند.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     30\u001b[0m frame_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> 31\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpose\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m keypoints \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:\n",
      "File \u001b[1;32mc:\\Users\\ML\\anaconda3\\envs\\xxxx\\lib\\site-packages\\mediapipe\\python\\solutions\\pose.py:185\u001b[0m, in \u001b[0;36mPose.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ML\\anaconda3\\envs\\xxxx\\lib\\site-packages\\mediapipe\\python\\solution_base.py:365\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    359\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    361\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    362\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    363\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 365\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m solution_outputs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mnamedtuple(\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolutionOutputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#مرحله ششم\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# مسیرهای ذخیره مدل‌ها و scaler و label encoder\n",
    "MODEL_PATH = \"lstm_model.h5\"\n",
    "SCALER_PATH = \"lstm_scaler.pkl\"\n",
    "LABEL_ENCODER_PATH = \"label_encoder.pkl\"\n",
    "\n",
    "# بارگذاری مدل، scaler و label encoder\n",
    "model = load_model(MODEL_PATH)\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "label_encoder = joblib.load(LABEL_ENCODER_PATH)\n",
    "\n",
    "# تنظیمات MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# تعداد نقاط کلیدی: فرض بر این است که 33 نقطه با 2 مختصات (x,y) استخراج می‌شود\n",
    "NUM_FEATURES = 33 * 2\n",
    "\n",
    "def extract_keypoints(frame):\n",
    "    \"\"\"\n",
    "    از یک فریم، نقاط کلیدی (x,y) بدن را استخراج می‌کند.\n",
    "    در صورت عدم شناسایی، یک آرایه از صفرها برمی‌گرداند.\n",
    "    \"\"\"\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(frame_rgb)\n",
    "    keypoints = []\n",
    "    if results.pose_landmarks:\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            keypoints.append(landmark.x)\n",
    "            keypoints.append(landmark.y)\n",
    "    else:\n",
    "        keypoints = [0.0] * NUM_FEATURES\n",
    "    return np.array(keypoints), results.pose_landmarks\n",
    "\n",
    "def predict_exercise_from_video(video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path if video_path else 0)  # اگر ویدیو موجود نباشد، از وب‌کم استفاده کن\n",
    "    if not cap.isOpened():\n",
    "        print(\"❌ خطا در باز کردن ویدیو.\")\n",
    "        return None\n",
    "\n",
    "    # تنظیم اندازه ویدیو\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # تغییر اندازه فریم (در صورت نیاز، همان اندازه‌ای که در آموزش استفاده شده، مثلاً 320x240)\n",
    "        frame_resized = cv2.resize(frame, (320, 240))\n",
    "\n",
    "        # استخراج نقاط کلیدی\n",
    "        keypoints, landmarks = extract_keypoints(frame_resized)\n",
    "        if keypoints.shape[0] != NUM_FEATURES:\n",
    "            print(\"❌ تعداد نقاط کلیدی استخراج‌شده نادرست است.\")\n",
    "            continue\n",
    "\n",
    "        # نرمال‌سازی داده‌ها با scaler ذخیره‌شده\n",
    "        input_scaled = scaler.transform(keypoints.reshape(1, -1))\n",
    "\n",
    "        # تغییر شکل به سه بعدی برای مدل (1, NUM_FEATURES, 1)\n",
    "        input_final = input_scaled.reshape(1, NUM_FEATURES, 1)\n",
    "\n",
    "        # پیش‌بینی با مدل\n",
    "        prediction_probs = model.predict(input_final)\n",
    "        predicted_index = np.argmax(prediction_probs, axis=1)[0]\n",
    "        predicted_label = label_encoder.inverse_transform([predicted_index])[0]\n",
    "\n",
    "        # نمایش نوع حرکت ورزشی تشخیص داده‌شده\n",
    "        cv2.putText(frame, f\"Predicted: {predicted_label}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # رسم نقاط کلیدی و خطوط بین نقاط\n",
    "        if landmarks:\n",
    "            for i in range(33):  # رسم نقاط کلیدی\n",
    "                x = int(landmarks.landmark[i].x * frame_width)\n",
    "                y = int(landmarks.landmark[i].y * frame_height)\n",
    "                cv2.circle(frame, (x, y), 5, (0, 255, 255), -1)  # نقاط کلیدی به رنگ زرد\n",
    "\n",
    "            # رسم خطوط بین نقاط کلیدی (وصل کردن نقاط مختلف بدن)\n",
    "            connections = mp_pose.POSE_CONNECTIONS\n",
    "            for connection in connections:\n",
    "                start_idx, end_idx = connection\n",
    "                start = landmarks.landmark[start_idx]\n",
    "                end = landmarks.landmark[end_idx]\n",
    "                start_coords = int(start.x * frame_width), int(start.y * frame_height)\n",
    "                end_coords = int(end.x * frame_width), int(end.y * frame_height)\n",
    "                cv2.line(frame, start_coords, end_coords, (0, 255,0), 2)  # خطوط به رنگ قرمز\n",
    "\n",
    "        # نمایش ویدیو\n",
    "        cv2.imshow(\"Exercise Feedback\", frame)\n",
    "\n",
    "        # زمانی که کاربر کلید 'q' را بزند، از ویدیو خارج می‌شود\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# استفاده از تابع برای ویدیو زنده یا ویدیوی بارگذاری شده\n",
    "video_file = \"ppp.mp4\"  # برای استفاده از ویدیو، این مسیر را مشخص کنید\n",
    "predict_exercise_from_video(video_file)  # برای استفاده از وب‌کم، ویدیو را خالی بگذارید یا None قرار دهید\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xxxx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
